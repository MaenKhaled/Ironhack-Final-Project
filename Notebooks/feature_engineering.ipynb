{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461f7ac-5822-4ae6-9ff7-44b2fead60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df =pd.read_csv(\"../Data/clean_data/cleaned_loan_updated.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf2960-3518-46b6-8415-d2ee7b4dc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.person_income_log.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20f7b3-e190-48e1-82ac-41b89b00c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding (Best for Nominal)\n",
    "# One-hot encode nominal features\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(\n",
    "    df,\n",
    "    columns=['person_home_ownership', 'loan_purpose', 'cb_person_default_on_file'],\n",
    "    drop_first=True,  # Reduces multicollinearity\n",
    "    dtype='int'      # Directly creates integer columns instead of boolean\n",
    ")\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"\\nNew columns after encoding:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "\n",
    "# Check the first few rows to confirm encoding worked\n",
    "print(\"\\nSample of encoded data:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df12922-05ba-4090-b63d-b539b06872d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Target Variable (loan_status)\n",
    "# Convert boolean to int (False=0, True=1)\n",
    "df_encoded['loan_status'] = df_encoded['loan_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6ca66-aef5-416a-81c1-d7fb59e9628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded.dtypes)\n",
    "print(df_encoded['loan_status'].value_counts())  # Should show 0 (False) and 1 (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda1910-9308-4acd-8c92-ca91a4a53741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7ed65-5e91-44c3-b3b5-283c49bcbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To impute the missing values of loan_interest_rate we will use \n",
    "# Predictive Modeling and Train a regression model (e.g., Random Forest) on complete cases to predict missing rates\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 3. PERFORM THE IMPUTATION\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split into complete/missing cases\n",
    "complete = df_encoded[df_encoded['loan_interest_rate'].notna()]\n",
    "missing = df_encoded[df_encoded['loan_interest_rate'].isna()]\n",
    "\n",
    "# Train model\n",
    "# Featurees to include in the model\n",
    "features = [\n",
    "    'person_age', 'person_income', 'person_employment_length', 'loan_amount',\n",
    "    'loan_status', 'loan_to_income_ratio', 'cb_credit_history_length',\n",
    "    'person_income_log', 'loan_amount_log', 'loan_grade_numeric',\n",
    "    'person_home_ownership_other', 'person_home_ownership_own', 'person_home_ownership_rent',\n",
    "    'loan_purpose_education', 'loan_purpose_home-improvement', 'loan_purpose_medical',\n",
    "    'loan_purpose_personal', 'loan_purpose_venture', 'cb_person_default_on_file_Y'\n",
    "]\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(complete[features], complete['loan_interest_rate'])\n",
    "\n",
    "# Impute missing values\n",
    "df_encoded.loc[missing.index, 'loan_interest_rate'] = rf.predict(missing[features])\n",
    "\n",
    "# 4. VERIFY RESULTS\n",
    "print(\"\\nMissing values after imputation:\", df_encoded['loan_interest_rate'].isna().sum())\n",
    "print(\"New value ranges:\", df_encoded['loan_interest_rate'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171ea53-0f03-42dd-a2e0-9cc9d344ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7669b5-9d2f-4f36-9831-92eb8eedec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical features (including encoded binary features)\n",
    "numerical_features = [\n",
    "    'person_age',\n",
    "    'person_income',\n",
    "    'person_employment_length',\n",
    "    'loan_amount',\n",
    "    'loan_interest_rate',\n",
    "    'loan_to_income_ratio',\n",
    "    'cb_credit_history_length',\n",
    "    'person_income_log',\n",
    "    'loan_amount_log',\n",
    "    'loan_grade_numeric',\n",
    "    'person_home_ownership_other',\n",
    "    'person_home_ownership_own',\n",
    "    'person_home_ownership_rent',\n",
    "    'loan_purpose_education',\n",
    "    'loan_purpose_home-improvement',\n",
    "    'loan_purpose_medical',\n",
    "    'loan_purpose_personal',\n",
    "    'loan_purpose_venture',\n",
    "    'cb_person_default_on_file_Y',\n",
    "    'loan_status'  # Target\n",
    "]\n",
    "\n",
    "# Create correlation matrix only for these features\n",
    "corr_matrix = df_encoded[numerical_features].corr()\n",
    "\n",
    "# Plot ONLY correlations with loan_status (vertical layout)\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.heatmap(corr_matrix[['loan_status']].sort_values('loan_status', ascending=False), \n",
    "            annot=True, fmt=\".2f\", cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation with Loan Status (Default)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d63222-be1e-4543-9235-3b88a46baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features (same as before)\n",
    "numerical_features = [\n",
    "    'person_age', 'person_income', 'person_employment_length',\n",
    "    'loan_amount', 'loan_interest_rate', 'loan_to_income_ratio',\n",
    "    'cb_credit_history_length', 'person_income_log', 'loan_amount_log',\n",
    "    'loan_grade_numeric',\n",
    "    # One-hot encoded features:\n",
    "    'person_home_ownership_rent', 'person_home_ownership_own',\n",
    "    'cb_person_default_on_file_Y', \n",
    "    'loan_status'  # Target\n",
    "]\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df_encoded[numerical_features].corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a mask to hide upper triangle (optional)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr_matrix, \n",
    "            mask=mask if 'mask' in locals() else None,\n",
    "            annot=True, fmt=\".2f\", \n",
    "            cmap='coolwarm', center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Matrix\", pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb365878-7360-4586-acbe-7514cadd33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a91d9a-ced2-4764-9ddc-7ed75c03c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preperation to train the model to predict the target\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y) - exclude non-feature columns\n",
    "X = df_encoded.drop(columns=[\n",
    "    'loan_status',         # Target variable\n",
    "    'loan_grade',          # Already encoded as loan_grade_numeric\n",
    "    'credit_history_bins'  # Categorical (optional: could encode if needed)\n",
    "])\n",
    "y = df_encoded['loan_status']\n",
    "\n",
    "# Verify feature columns\n",
    "print(\"Features being used:\\n\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff0f32-c52a-453b-aad7-0c18f9f0a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split:\n",
    "# Stratified split (maintains 78%/22% ratio in both sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Critical for imbalanced data\n",
    ")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass counts in y_train:\", y_train.value_counts())\n",
    "print(\"Class counts in y_test:\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c44b9-2eea-4b0b-bb6e-42ab34e54f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Scaling (Only Numerical Features)\n",
    "# Identify numerical columns (excluding already binary-encoded ones)\n",
    "num_cols = [\n",
    "    'person_age', \n",
    "    'person_income', \n",
    "    'person_employment_length',\n",
    "    'loan_amount', \n",
    "    'loan_interest_rate', \n",
    "    'loan_to_income_ratio',\n",
    "    'cb_credit_history_length', \n",
    "    'person_income_log', \n",
    "    'loan_amount_log',\n",
    "    'loan_grade_numeric'  # Ordinal encoded\n",
    "]\n",
    "\n",
    "# Scale numerical features (preserves binary columns)\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Verify scaling\n",
    "print(\"\\nScaled features (sample):\\n\", X_train[num_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324e643-3043-4879-925d-bc638c7e8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models training and evaluation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize models with class weighting\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        class_weight='balanced',  # Adjusts for 78%/22% imbalance\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',  # Adjusts for imbalance\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Evaluation on Test Set ---\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # --- Evaluation on Train Set ---\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Store both train and test results\n",
    "    results[name] = {\n",
    "        \"test_report\": classification_report(y_test, y_test_pred),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"train_report\": classification_report(y_train, y_train_pred),\n",
    "        \"train_roc_auc\": roc_auc_score(y_train, y_train_proba),\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(\"TRAIN SET:\")\n",
    "    print(metrics[\"train_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['train_roc_auc']:.4f}\")\n",
    "    print(\"TEST SET:\")\n",
    "    print(metrics[\"test_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79a3e2-484e-44c2-9e68-454041e2ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e484a-ca4b-4c4e-a908-74773c63a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.person_age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ee48-575d-4953-abc1-653caa2a8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why These Bins?\n",
    "## It is clearly that the majorty of the data has age lower than 30 years that why we decided to mkae the following bins:\n",
    "\n",
    "# Define bin edges (inclusive on left, exclusive on right by default)\n",
    "bins = [20, 25, 30, 35, 40, 45, 50]\n",
    "labels = ['21-25', '26-30', '31-35', '36-40', '41-45', '46-50']\n",
    "\n",
    "# Create a new binned column\n",
    "df_encoded['person_age_bins'] = pd.cut(df_encoded['person_age'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Check for missing values (should be 0)\n",
    "print(\"Missing values in binned column:\", df_encoded['person_age_bins'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb05f5-1c0d-4406-b317-e633ea512587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.person_income.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c110f-5c42-4a0c-82f6-30d6ba532dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why These Bins?\n",
    "## Very Low (<$38.5K): Bottom 25% - Likely higher risk\n",
    "\n",
    "## Low ($38.5K-$55K): Below median income\n",
    "\n",
    "## Medium ($55K-$79.2K): Middle-income borrowers\n",
    "\n",
    "## High ($79.2K-$100K): Top 25% excluding highest earners\n",
    "\n",
    "## Very High (>$100K): Top ~15% (79218-225000 covers 75th-100th percentile)\n",
    "\n",
    "income_bins = [14400, 38542, 55000, 79218, 100000, 225000]  # Based on percentiles + round numbers\n",
    "income_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "df_encoded['income_group'] = pd.cut(\n",
    "    df_encoded['person_income'],\n",
    "    bins=income_bins,\n",
    "    labels=income_labels,\n",
    "    include_lowest=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd425f0-785d-4381-9229-cefac0ff0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Income Group Distribution:\")\n",
    "print(df_encoded['income_group'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDefault Rates by Income Group:\")\n",
    "print(df_encoded.groupby('income_group')['loan_status'].mean().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a16391-f633-4d52-adba-c3c8a0fbc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# Default rate by income group\n",
    "df_encoded.groupby('income_group')['loan_status'].mean().sort_values().plot(\n",
    "    kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Default Rate by Income Group')\n",
    "plt.ylabel('Default Rate')\n",
    "plt.axhline(y=df_encoded['loan_status'].mean(), color='red', linestyle='--', \n",
    "            label=f'Overall Default Rate ({df_encoded[\"loan_status\"].mean():.1%})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c4c03-c11d-49b0-b7dd-7772977b5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.drop(columns='age_group', inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd087f-de23-497e-9233-230a95c2d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983bd14-79cb-46fc-9a4b-74bfaeac8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.person_age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d86e6-65a1-403f-a333-3e7e2d3d564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['income_group', 'person_age_bins'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569f9f8-97ee-473f-a428-f5f0b36808fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_encoded.drop(columns=['loan_status', 'loan_grade', 'credit_history_bins', 'income_group', 'person_age_bins'])\n",
    "y = df_encoded['loan_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aecbd-b8aa-4adb-b158-f5c57a89d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    " #   X, y, test_size=0.2, stratify=y, random_state=42\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988751b-49b0-4119-b8b6-7dcb7e421e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        \"test_report\": classification_report(y_test, y_test_pred),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"train_report\": classification_report(y_train, y_train_pred),\n",
    "        \"train_roc_auc\": roc_auc_score(y_train, y_train_proba),\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(\"TRAIN SET:\")\n",
    "    print(metrics[\"train_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['train_roc_auc']:.4f}\")\n",
    "    print(\"TEST SET:\")\n",
    "    print(metrics[\"test_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a704d-5e4d-40fe-aba2-cccffe1b19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def manual_oversample(X_train, y_train, target_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Manually oversamples minority class to reach target ratio\n",
    "    target_ratio = minority_count / majority_count\n",
    "    \"\"\"\n",
    "    # Separate classes\n",
    "    X_majority = X_train[y_train == 0]\n",
    "    X_minority = X_train[y_train == 1]\n",
    "    y_majority = y_train[y_train == 0]\n",
    "    y_minority = y_train[y_train == 1]\n",
    "    \n",
    "    # Calculate needed samples\n",
    "    n_majority = len(X_majority)\n",
    "    n_minority_target = int(n_majority * target_ratio)\n",
    "    n_to_sample = n_minority_target - len(X_minority)\n",
    "    \n",
    "    # Oversample minority\n",
    "    X_minority_upsampled = resample(\n",
    "        X_minority,\n",
    "        replace=True,  # Sample with replacement\n",
    "        n_samples=n_to_sample,\n",
    "        random_state=42\n",
    "    )\n",
    "    y_minority_upsampled = pd.Series(1).repeat(n_to_sample)\n",
    "    \n",
    "    # Combine\n",
    "    X_resampled = pd.concat([X_train, X_minority_upsampled])\n",
    "    y_resampled = pd.concat([y_train, y_minority_upsampled])\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Usage\n",
    "X_train_res, y_train_res = manual_oversample(X_train, y_train, target_ratio=0.5)\n",
    "print(\"New class balance:\", y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcb2e0-b010-4a4e-929c-9141697c3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "# Initialize results dictionary at the START\n",
    "results = {}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train on manually resampled data\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # Evaluate on original test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate on resampled training data\n",
    "    y_train_res_pred = model.predict(X_train_res)\n",
    "    y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        \"test_report\": classification_report(y_test, y_test_pred),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "        \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison (After Manual Oversampling):\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(\"TRAIN SET (Resampled):\")\n",
    "    print(metrics[\"train_resampled_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['train_resampled_roc_auc']:.4f}\")\n",
    "    print(\"\\nTEST SET (Original):\")\n",
    "    print(metrics[\"test_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")\n",
    "    print(\"-\" * 50)  # Properly separated now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019269c5-e6d5-4eec-8dc1-cf221ddc4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. KNN Improvements\n",
    "# A. Feature Scaling (critical for KNN)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# B. Optimize k-value\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': [3,5,7,9,15], \n",
    "              'weights': ['uniform', 'distance']}\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(X_train_scaled, y_train_res)\n",
    "print(f\"Best params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8981e-5b37-417a-aa0e-dbf7c05a32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Logistic Regression Improvements\n",
    "## Weakness: Low precision for defaults (0.54) - too many false positives\n",
    "# A. Threshold adjustment (trade recall for precision)\n",
    "# 1. First ensure you have this in your model dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    # ... other models\n",
    "}\n",
    "\n",
    "# 2. After training (model.fit), use this for threshold adjustment:\n",
    "logreg = models[\"Logistic Regression\"].fit(X_train_scaled, y_train_res)  # Get the trained model\n",
    "\n",
    "# Get predicted probabilities for test set\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find optimal threshold for precision >= 0.7\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Find first threshold where precision >= 0.7\n",
    "optimal_idx = next(i for i, p in enumerate(precision) if p >= 0.7)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Apply adjusted threshold\n",
    "y_pred_adj = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nAdjusted Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_adj))\n",
    "print(f\"New threshold: {optimal_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba77569-dd2a-40e1-aadd-c16534af4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Improvements\n",
    "## Weakness: Overfitting (train AUC=1.0 vs test=0.938) and recall for defaults (0.73)\n",
    "# A. Reduce overfitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,  # Increase from 100\n",
    "    max_depth=10,       # Limit tree depth\n",
    "    min_samples_leaf=5, # Require more samples per leaf\n",
    "    class_weight='balanced_subsample',  # Better for imbalanced data\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# B. Feature importance analysis\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "pd.DataFrame({'feature':X.columns, 'importance':importances, 'std':std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7879f6-499c-4994-a972-cd1b63c73d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define tuned Random Forest model\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = rf.predict(X_train_res)\n",
    "y_train_res_proba = rf.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"Random Forest (Tuned)\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation: Random Forest (Tuned)\")\n",
    "metrics = results[\"Random Forest (Tuned)\"]\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(metrics[\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {metrics['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(metrics[\"test_report\"])\n",
    "print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daf9f3-62b7-4b87-b71b-9e1c1b686d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Set up the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='f1',  # or 'roc_auc', 'precision', etc.\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265af34c-96f7-4fa7-8a3a-acbd3696f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define tuned Random Forest model\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = rf.predict(X_train_res)\n",
    "y_train_res_proba = rf.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"Random Forest (Tuned)\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation: Random Forest (Tuned)\")\n",
    "metrics = results[\"Random Forest (Tuned)\"]\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(metrics[\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {metrics['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(metrics[\"test_report\"])\n",
    "print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d51824-b66b-4382-b5d6-606c55ede662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define tuned Random Forest model\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight={0: 1, 1: 2},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = rf.predict(X_train_res)\n",
    "y_train_res_proba = rf.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"Random Forest (Tuned)\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation: Random Forest (Tuned)\")\n",
    "metrics = results[\"Random Forest (Tuned)\"]\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(metrics[\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {metrics['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(metrics[\"test_report\"])\n",
    "print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80cc36-5f32-4a57-a225-c15a99b41b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
