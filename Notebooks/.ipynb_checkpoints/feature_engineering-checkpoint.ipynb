{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461f7ac-5822-4ae6-9ff7-44b2fead60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df =pd.read_csv(\"../Data/clean_data/cleaned_loan_updated.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf2960-3518-46b6-8415-d2ee7b4dc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.person_income_log.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20f7b3-e190-48e1-82ac-41b89b00c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding (Best for Nominal)\n",
    "# One-hot encode nominal features\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(\n",
    "    df,\n",
    "    columns=['person_home_ownership', 'loan_purpose', 'cb_person_default_on_file'],\n",
    "    drop_first=True,  # Reduces multicollinearity\n",
    "    dtype='int'      # Directly creates integer columns instead of boolean\n",
    ")\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"\\nNew columns after encoding:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "\n",
    "# Check the first few rows to confirm encoding worked\n",
    "print(\"\\nSample of encoded data:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df12922-05ba-4090-b63d-b539b06872d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Target Variable (loan_status)\n",
    "# Convert boolean to int (False=0, True=1)\n",
    "df_encoded['loan_status'] = df_encoded['loan_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6ca66-aef5-416a-81c1-d7fb59e9628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded.dtypes)\n",
    "print(df_encoded['loan_status'].value_counts())  # Should show 0 (False) and 1 (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda1910-9308-4acd-8c92-ca91a4a53741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7ed65-5e91-44c3-b3b5-283c49bcbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To impute the missing values of loan_interest_rate we will use \n",
    "# Predictive Modeling and Train a regression model (e.g., Random Forest) on complete cases to predict missing rates\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 3. PERFORM THE IMPUTATION\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split into complete/missing cases\n",
    "complete = df_encoded[df_encoded['loan_interest_rate'].notna()]\n",
    "missing = df_encoded[df_encoded['loan_interest_rate'].isna()]\n",
    "\n",
    "# Train model\n",
    "# Featurees to include in the model\n",
    "features = [\n",
    "    'person_age', 'person_income', 'person_employment_length', 'loan_amount',\n",
    "    'loan_status', 'loan_to_income_ratio', 'cb_credit_history_length',\n",
    "    'person_income_log', 'loan_amount_log', 'loan_grade_numeric',\n",
    "    'person_home_ownership_other', 'person_home_ownership_own', 'person_home_ownership_rent',\n",
    "    'loan_purpose_education', 'loan_purpose_home-improvement', 'loan_purpose_medical',\n",
    "    'loan_purpose_personal', 'loan_purpose_venture', 'cb_person_default_on_file_Y'\n",
    "]\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(complete[features], complete['loan_interest_rate'])\n",
    "\n",
    "# Impute missing values\n",
    "df_encoded.loc[missing.index, 'loan_interest_rate'] = rf.predict(missing[features])\n",
    "\n",
    "# 4. VERIFY RESULTS\n",
    "print(\"\\nMissing values after imputation:\", df_encoded['loan_interest_rate'].isna().sum())\n",
    "print(\"New value ranges:\", df_encoded['loan_interest_rate'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171ea53-0f03-42dd-a2e0-9cc9d344ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7669b5-9d2f-4f36-9831-92eb8eedec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical features (including encoded binary features)\n",
    "numerical_features = [\n",
    "    'person_age',\n",
    "    'person_income',\n",
    "    'person_employment_length',\n",
    "    'loan_amount',\n",
    "    'loan_interest_rate',\n",
    "    'loan_to_income_ratio',\n",
    "    'cb_credit_history_length',\n",
    "    'person_income_log',\n",
    "    'loan_amount_log',\n",
    "    'loan_grade_numeric',\n",
    "    'person_home_ownership_other',\n",
    "    'person_home_ownership_own',\n",
    "    'person_home_ownership_rent',\n",
    "    'loan_purpose_education',\n",
    "    'loan_purpose_home-improvement',\n",
    "    'loan_purpose_medical',\n",
    "    'loan_purpose_personal',\n",
    "    'loan_purpose_venture',\n",
    "    'cb_person_default_on_file_Y',\n",
    "    'loan_status'  # Target\n",
    "]\n",
    "\n",
    "# Create correlation matrix only for these features\n",
    "corr_matrix = df_encoded[numerical_features].corr()\n",
    "\n",
    "# Plot ONLY correlations with loan_status (vertical layout)\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.heatmap(corr_matrix[['loan_status']].sort_values('loan_status', ascending=False), \n",
    "            annot=True, fmt=\".2f\", cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation with Loan Status (Default)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d63222-be1e-4543-9235-3b88a46baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features (same as before)\n",
    "numerical_features = [\n",
    "    'person_age', 'person_income', 'person_employment_length',\n",
    "    'loan_amount', 'loan_interest_rate', 'loan_to_income_ratio',\n",
    "    'cb_credit_history_length', 'person_income_log', 'loan_amount_log',\n",
    "    'loan_grade_numeric',\n",
    "    # One-hot encoded features:\n",
    "    'person_home_ownership_rent', 'person_home_ownership_own',\n",
    "    'cb_person_default_on_file_Y', \n",
    "    'loan_status'  # Target\n",
    "]\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df_encoded[numerical_features].corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a mask to hide upper triangle (optional)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr_matrix, \n",
    "            mask=mask if 'mask' in locals() else None,\n",
    "            annot=True, fmt=\".2f\", \n",
    "            cmap='coolwarm', center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Matrix\", pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb365878-7360-4586-acbe-7514cadd33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a91d9a-ced2-4764-9ddc-7ed75c03c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preperation to train the model to predict the target\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y) - exclude non-feature columns\n",
    "X = df_encoded.drop(columns=[\n",
    "    'loan_status',         # Target variable\n",
    "    'loan_grade',          # Already encoded as loan_grade_numeric\n",
    "    'credit_history_bins'  # Categorical (optional: could encode if needed)\n",
    "])\n",
    "y = df_encoded['loan_status']\n",
    "\n",
    "# Verify feature columns\n",
    "print(\"Features being used:\\n\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff0f32-c52a-453b-aad7-0c18f9f0a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split:\n",
    "# Stratified split (maintains 78%/22% ratio in both sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Critical for imbalanced data\n",
    ")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass counts in y_train:\", y_train.value_counts())\n",
    "print(\"Class counts in y_test:\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c44b9-2eea-4b0b-bb6e-42ab34e54f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Scaling (Only Numerical Features)\n",
    "# Identify numerical columns (excluding already binary-encoded ones)\n",
    "num_cols = [\n",
    "    'person_age', \n",
    "    'person_income', \n",
    "    'person_employment_length',\n",
    "    'loan_amount', \n",
    "    'loan_interest_rate', \n",
    "    'loan_to_income_ratio',\n",
    "    'cb_credit_history_length', \n",
    "    'person_income_log', \n",
    "    'loan_amount_log',\n",
    "    'loan_grade_numeric'  # Ordinal encoded\n",
    "]\n",
    "\n",
    "# Scale numerical features (preserves binary columns)\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Verify scaling\n",
    "print(\"\\nScaled features (sample):\\n\", X_train[num_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324e643-3043-4879-925d-bc638c7e8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models training and evaluation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize models with class weighting\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        class_weight='balanced',  # Adjusts for 78%/22% imbalance\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',  # Adjusts for imbalance\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Evaluation on Test Set ---\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # --- Evaluation on Train Set ---\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Store both train and test results\n",
    "    results[name] = {\n",
    "        \"test_report\": classification_report(y_test, y_test_pred),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"train_report\": classification_report(y_train, y_train_pred),\n",
    "        \"train_roc_auc\": roc_auc_score(y_train, y_train_proba),\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(\"TRAIN SET:\")\n",
    "    print(metrics[\"train_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['train_roc_auc']:.4f}\")\n",
    "    print(\"TEST SET:\")\n",
    "    print(metrics[\"test_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79a3e2-484e-44c2-9e68-454041e2ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e484a-ca4b-4c4e-a908-74773c63a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_encoded.person_age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ee48-575d-4953-abc1-653caa2a8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why These Bins?\n",
    "## It is clearly that the majorty of the data has age lower than 30 years that why we decided to mkae the following bins:\n",
    "\n",
    "# Define bin edges (inclusive on left, exclusive on right by default)\n",
    "#bins = [20, 25, 30, 35, 40, 45, 50]\n",
    "#labels = ['21-25', '26-30', '31-35', '36-40', '41-45', '46-50']\n",
    "\n",
    "# Create a new binned column\n",
    "#df_encoded['person_age_bins'] = pd.cut(df_encoded['person_age'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Check for missing values (should be 0)\n",
    "#print(\"Missing values in binned column:\", df_encoded['person_age_bins'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb05f5-1c0d-4406-b317-e633ea512587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.person_income.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c110f-5c42-4a0c-82f6-30d6ba532dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why These Bins?\n",
    "## Very Low (<$38.5K): Bottom 25% - Likely higher risk\n",
    "\n",
    "## Low ($38.5K-$55K): Below median income\n",
    "\n",
    "## Medium ($55K-$79.2K): Middle-income borrowers\n",
    "\n",
    "## High ($79.2K-$100K): Top 25% excluding highest earners\n",
    "\n",
    "## Very High (>$100K): Top ~15% (79218-225000 covers 75th-100th percentile)\n",
    "\n",
    "#income_bins = [14400, 38542, 55000, 79218, 100000, 225000]  # Based on percentiles + round numbers\n",
    "#income_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "#df_encoded['income_group'] = pd.cut(\n",
    "  #  df_encoded['person_income'],\n",
    "  #  bins=income_bins,\n",
    "  #  labels=income_labels,\n",
    "  #  include_lowest=True\n",
    "   # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd425f0-785d-4381-9229-cefac0ff0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Income Group Distribution:\")\n",
    "# print(df_encoded['income_group'].value_counts().sort_index())\n",
    "\n",
    "# print(\"\\nDefault Rates by Income Group:\")\n",
    "# print(df_encoded.groupby('income_group')['loan_status'].mean().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a16391-f633-4d52-adba-c3c8a0fbc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10,6))\n",
    "# Default rate by income group\n",
    "# df_encoded.groupby('income_group')['loan_status'].mean().sort_values().plot(\n",
    "#     kind='bar', color='skyblue', edgecolor='black')\n",
    "# plt.title('Default Rate by Income Group')\n",
    "# plt.ylabel('Default Rate')\n",
    "# plt.axhline(y=df_encoded['loan_status'].mean(), color='red', linestyle='--', \n",
    "#             label=f'Overall Default Rate ({df_encoded[\"loan_status\"].mean():.1%})')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c4c03-c11d-49b0-b7dd-7772977b5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.drop(columns='age_group', inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd087f-de23-497e-9233-230a95c2d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983bd14-79cb-46fc-9a4b-74bfaeac8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.person_age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d86e6-65a1-403f-a333-3e7e2d3d564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "# df_encoded = pd.get_dummies(df_encoded, columns=['income_group', 'person_age_bins'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569f9f8-97ee-473f-a428-f5f0b36808fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# X = df_encoded.drop(columns=['loan_status', 'loan_grade', 'credit_history_bins', 'income_group', 'person_age_bins'])\n",
    "# y = df_encoded['loan_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aecbd-b8aa-4adb-b158-f5c57a89d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    " #   X, y, test_size=0.2, stratify=y, random_state=42\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988751b-49b0-4119-b8b6-7dcb7e421e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models = {\n",
    " #    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    " #    \"Logistic Regression\": LogisticRegression(\n",
    "    #    max_iter=1000,\n",
    "     #   class_weight='balanced',\n",
    "      #  random_state=42\n",
    "   # ),\n",
    "  #  \"Random Forest\": RandomForestClassifier(\n",
    "  #      n_estimators=100,\n",
    "   #     class_weight='balanced',\n",
    "   #     random_state=42\n",
    "  #  )\n",
    "#}\n",
    "\n",
    "#results = {}\n",
    "#for name, model in models.items():\n",
    "#    model.fit(X_train, y_train)\n",
    "    \n",
    " #   y_test_pred = model.predict(X_test)\n",
    " #   y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    " #   y_train_pred = model.predict(X_train)\n",
    " #   y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "  #  results[name] = {\n",
    "  #      \"test_report\": classification_report(y_test, y_test_pred),\n",
    "  #      \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "  #      \"train_report\": classification_report(y_train, y_train_pred),\n",
    "  #      \"train_roc_auc\": roc_auc_score(y_train, y_train_proba),\n",
    " #   }\n",
    "\n",
    "# Print results\n",
    "# print(\"\\nModel Comparison Results:\")\n",
    "# for name, metrics in results.items():\n",
    "#    print(f\"\\n----- {name} -----\")\n",
    "#    print(\"TRAIN SET:\")\n",
    "#    print(metrics[\"train_report\"])\n",
    "#    print(f\"ROC-AUC: {metrics['train_roc_auc']:.4f}\")\n",
    " #   print(\"TEST SET:\")\n",
    " #   print(metrics[\"test_report\"])\n",
    "  #  print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a704d-5e4d-40fe-aba2-cccffe1b19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def manual_oversample(X_train, y_train, target_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Manually oversamples minority class to reach target ratio\n",
    "    target_ratio = minority_count / majority_count\n",
    "    \"\"\"\n",
    "    # Separate classes\n",
    "    X_majority = X_train[y_train == 0]\n",
    "    X_minority = X_train[y_train == 1]\n",
    "    y_majority = y_train[y_train == 0]\n",
    "    y_minority = y_train[y_train == 1]\n",
    "    \n",
    "    # Calculate needed samples\n",
    "    n_majority = len(X_majority)\n",
    "    n_minority_target = int(n_majority * target_ratio)\n",
    "    n_to_sample = n_minority_target - len(X_minority)\n",
    "    \n",
    "    # Oversample minority\n",
    "    X_minority_upsampled = resample(\n",
    "        X_minority,\n",
    "        replace=True,  # Sample with replacement\n",
    "        n_samples=n_to_sample,\n",
    "        random_state=42\n",
    "    )\n",
    "    y_minority_upsampled = pd.Series(1).repeat(n_to_sample)\n",
    "    \n",
    "    # Combine\n",
    "    X_resampled = pd.concat([X_train, X_minority_upsampled])\n",
    "    y_resampled = pd.concat([y_train, y_minority_upsampled])\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Usage\n",
    "X_train_res, y_train_res = manual_oversample(X_train, y_train, target_ratio=0.5)\n",
    "print(\"New class balance:\", y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcb2e0-b010-4a4e-929c-9141697c3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "# Initialize results dictionary at the START\n",
    "results = {}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train on manually resampled data\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # Evaluate on original test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate on resampled training data\n",
    "    y_train_res_pred = model.predict(X_train_res)\n",
    "    y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        \"test_report\": classification_report(y_test, y_test_pred),\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "        \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison (After Manual Oversampling):\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(\"TRAIN SET (Resampled):\")\n",
    "    print(metrics[\"train_resampled_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['train_resampled_roc_auc']:.4f}\")\n",
    "    print(\"\\nTEST SET (Original):\")\n",
    "    print(metrics[\"test_report\"])\n",
    "    print(f\"ROC-AUC: {metrics['test_roc_auc']:.4f}\")\n",
    "    print(\"-\" * 50)  # Properly separated now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019269c5-e6d5-4eec-8dc1-cf221ddc4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. KNN Improvements\n",
    "# A. Feature Scaling (critical for KNN)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# B. Optimize k-value\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': [3,5,7,9,15], \n",
    "              'weights': ['uniform', 'distance']}\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(X_train_scaled, y_train_res)\n",
    "print(f\"Best params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80cc36-5f32-4a57-a225-c15a99b41b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define the best KNN model\n",
    "model = KNeighborsClassifier(\n",
    "    n_neighbors=15,\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = model.predict(X_train_res)\n",
    "y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"KNN\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nKNN Model Performance (After Manual Oversampling):\")\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(results[\"KNN\"][\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {results['KNN']['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(results[\"KNN\"][\"test_report\"])\n",
    "print(f\"ROC-AUC: {results['KNN']['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41528d1a-2f9e-42f9-973e-e9d4ad1d3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['liblinear', 'saga'],  # supports l1 and elasticnet\n",
    "    'class_weight': ['balanced']  # keep balanced since dataset is imbalanced\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on resampled training data\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC-AUC score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e1ff8-b747-4231-8d06-b0cdb9c2d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define the best Logistic Regression model\n",
    "model = LogisticRegression(\n",
    "    C=0.1,\n",
    "    class_weight='balanced',\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = model.predict(X_train_res)\n",
    "y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"Logistic Regression\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nLogistic Regression Model Performance (After Manual Oversampling):\")\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(results[\"Logistic Regression\"][\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {results['Logistic Regression']['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(results[\"Logistic Regression\"][\"test_report\"])\n",
    "print(f\"ROC-AUC: {results['Logistic Regression']['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe541d44-0e9f-44c2-be06-e39d6466b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Grid search setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,   # smaller CV for speed, can increase to 5 for more accuracy\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit on resampled training data\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best parameters & score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC-AUC score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699978e-e2ad-4217-83d9-43e77986b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Define the best Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = model.predict(X_train_res)\n",
    "y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"Random Forest\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRandom Forest Model Performance (After Manual Oversampling):\")\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(results[\"Random Forest\"][\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {results['Random Forest']['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(results[\"Random Forest\"][\"test_report\"])\n",
    "print(f\"ROC-AUC: {results['Random Forest']['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dff1f5-1243-4893-83c6-285e5bada7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f56fa8-54c2-4dcf-98bf-07bb6269240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,  # no limit\n",
    "    num_leaves=31,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on manually resampled data\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on original test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate on resampled training data\n",
    "y_train_res_pred = model.predict(X_train_res)\n",
    "y_train_res_proba = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results[\"LightGBM\"] = {\n",
    "    \"test_report\": classification_report(y_test, y_test_pred),\n",
    "    \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"train_resampled_report\": classification_report(y_train_res, y_train_res_pred),\n",
    "    \"train_resampled_roc_auc\": roc_auc_score(y_train_res, y_train_res_proba)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nLightGBM Model Performance (After Manual Oversampling):\")\n",
    "print(\"TRAIN SET (Resampled):\")\n",
    "print(results[\"LightGBM\"][\"train_resampled_report\"])\n",
    "print(f\"ROC-AUC: {results['LightGBM']['train_resampled_roc_auc']:.4f}\")\n",
    "print(\"\\nTEST SET (Original):\")\n",
    "print(results[\"LightGBM\"][\"test_report\"])\n",
    "print(f\"ROC-AUC: {results['LightGBM']['test_roc_auc']:.4f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661baa5-de0d-4a60-8f3e-e3ea21db8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbf38a-87e2-48d6-ba59-f4152f4f8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To improve the recall rate for your model (especially for the critical Class 1 - Default),\n",
    "# we should use a combination of the following approaches, ranked by effectiveness for your use case:\n",
    "## Best Options to Maximize Recall (Prioritizing Default Detection)\n",
    "## 1. precision_recall_curve + Threshold Adjustment\n",
    "## What it does:\n",
    "\n",
    "## Computes precision-recall pairs for different probability thresholds.\n",
    "\n",
    "## Lets you manually select a threshold that maximizes recall (even if precision drops).\n",
    "\n",
    "## Why use it?\n",
    "\n",
    "## Directly targets the recall-precision trade-off.\n",
    "\n",
    "## You can set a minimum recall (e.g., 90%) and accept lower precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad553d5-e765-4b62-a3d0-8db557ccd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import (classification_report, \n",
    "                           roc_auc_score, \n",
    "                           precision_recall_curve,\n",
    "                           recall_score,\n",
    "                           precision_score,  # Added missing import\n",
    "                           make_scorer)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# =============================================\n",
    "# 1. Define Threshold Finder Function\n",
    "# =============================================\n",
    "\n",
    "def find_optimal_threshold(y_true, y_probs, target_recall):\n",
    "    \"\"\"Finds the threshold that achieves at least target recall\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "    \n",
    "    # Get last threshold where recall >= target (using recall[:-1] to match lengths)\n",
    "    try:\n",
    "        best_idx = np.where(recall[:-1] >= target_recall)[0][-1]\n",
    "        return thresholds[best_idx]\n",
    "    except IndexError:\n",
    "        max_recall = recall.max()\n",
    "        print(f\"Warning: Cannot achieve {target_recall:.0%} recall. Max recall is {max_recall:.2%}\")\n",
    "        return thresholds[np.argmax(recall[:-1])]\n",
    "\n",
    "# =============================================\n",
    "# 2. Initialize and Train Model\n",
    "# =============================================\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    num_leaves=31,\n",
    "    class_weight={0:1, 1:3},  # Higher weight for default class\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on resampled data\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# =============================================\n",
    "# 3. Threshold Tuning\n",
    "# =============================================\n",
    "\n",
    "# Get predicted probabilities for Class 1\n",
    "y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find optimal threshold for 90% recall\n",
    "optimal_threshold = find_optimal_threshold(y_test, y_test_probs, 0.90)\n",
    "\n",
    "print(f\"\\nOptimal threshold for 90% recall: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Generate high-recall predictions\n",
    "y_pred_high_recall = (y_test_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Verify achieved recall\n",
    "achieved_recall = recall_score(y_test, y_pred_high_recall, pos_label=1)\n",
    "print(f\"Achieved recall: {achieved_recall:.2%}\")\n",
    "\n",
    "# =============================================\n",
    "# 4. Grid Search with Recall Optimization\n",
    "# =============================================\n",
    "\n",
    "# Define custom scorer\n",
    "recall_scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'class_weight': [{0:1, 1:3}, {0:1, 1:5}]\n",
    "}\n",
    "\n",
    "# Run grid search on RESAMPLED data\n",
    "grid = GridSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(n_estimators=200, random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=recall_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# =============================================\n",
    "# 5. Evaluate All Models\n",
    "# =============================================\n",
    "\n",
    "def evaluate_model(name, model, X, y, threshold=0.5):\n",
    "    \"\"\"Helper function for evaluation\"\"\"\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(classification_report(y, preds))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y, probs):.4f}\")\n",
    "    print(f\"Default Rate in Predictions: {preds.mean():.2%}\")\n",
    "    return preds\n",
    "\n",
    "# Evaluate initial model with tuned threshold\n",
    "print(\"\\n=== Initial Model with Threshold Tuning ===\")\n",
    "evaluate_model(\"Tuned Model\", model, X_test, y_test, optimal_threshold)\n",
    "\n",
    "# Evaluate best grid search model\n",
    "print(\"\\n=== Best GridSearch Model ===\")\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(\"GridSearch Best\", best_model, X_test, y_test)\n",
    "\n",
    "# =============================================\n",
    "# 6. Compare Threshold Options\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nThreshold Comparison:\")\n",
    "for threshold in [0.3, 0.5, optimal_threshold]:\n",
    "    preds = (y_test_probs >= threshold).astype(int)\n",
    "    rec = recall_score(y_test, preds, pos_label=1)\n",
    "    prec = precision_score(y_test, preds, pos_label=1)  # Now works with imported precision_score\n",
    "    print(f\"Threshold {threshold:.2f}: Recall={rec:.2f}, Precision={prec:.2f}\")\n",
    "\n",
    "# =============================================\n",
    "# 7. Final Model Selection\n",
    "# =============================================\n",
    "\n",
    "# Choose your preferred model (uncomment one):\n",
    "# final_model = model  # Initial model with tuned threshold\n",
    "final_model = best_model  # GridSearch's best model\n",
    "\n",
    "print(\"\\nFinal model selected:\", final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88523027-2363-4573-a41c-1adb9b43eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16affe-1f82-4bfd-bdaf-3d26554c4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('encoded_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abe83c-25b7-4559-990c-0bc61afe1106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
